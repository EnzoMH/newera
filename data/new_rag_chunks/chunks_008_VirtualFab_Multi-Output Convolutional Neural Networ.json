{
  "source": "ArXiv",
  "filename": "008_VirtualFab_Multi-Output Convolutional Neural Networ.pdf",
  "domain": "VirtualFab",
  "total_chars": 64195,
  "total_chunks": 2,
  "chunks": [
    {
      "id": 44,
      "content": "d relatively larger kernels learn patterns in the slower features, \nlike the cantilever relaxation. In the fast and slow branches, we employ residual block layers to \nimprove deep learning efficiency and gradient optimization for small variations in input data.28,34,37 \nThe weight branch is strictly a convolutional neural network, which we found best approximated \nthe relative contributions from fast and slow processes.",
      "size": 423,
      "sentences": 2,
      "keyword_count": 2,
      "is_relevant": true
    },
    {
      "id": 123,
      "content": "0.1038/s41524-019-0148-5. (30) Fawaz, H. I.; Forestier, G.; Weber, J.; Idoumghar, L.; Muller, P.-A. Deep Learning for Time \nSeries Classification: A Review. Data Min Knowl Discov 2019, 33, 917â€“963. https://doi.org/10.48550/arXiv.1809.04356. === Page 16 ===\n16 \n \n(31) Karatay, D. U.; Harrison, J. S.; Glaz, M. S.; Giridharagopal, R.; Ginger, D. S. Fast Time-\nResolved Electrostatic Force Microscopy: Achieving Sub-Cycle Time Resolution. Rev. Sci. Instrum.",
      "size": 455,
      "sentences": 9,
      "keyword_count": 2,
      "is_relevant": true
    }
  ]
}