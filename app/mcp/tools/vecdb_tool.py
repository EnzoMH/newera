"""
VectorDB ê´€ë¦¬ MCP Tool
FAISS Vector DB ê´€ë¦¬ ê¸°ëŠ¥ ì œê³µ
"""
import asyncio
import logging
from typing import Dict, Any, List
from pathlib import Path
import json

from ..config import MCPConfig

logger = logging.getLogger(__name__)


class VectorDBTool:
    """VectorDB ê´€ë¦¬ MCP Tool"""

    def __init__(self, config: MCPConfig):
        self.config = config
        self.tool_config = config.get_tool_config("vector_db")

    def get_tool_schema(self) -> Dict[str, Any]:
        """MCP Tool ìŠ¤í‚¤ë§ˆ ë°˜í™˜"""
        return {
            "name": "vector_db",
            "description": "FAISS Vector DB ìƒì„±, ê²€ìƒ‰, ê´€ë¦¬",
            "inputSchema": {
                "type": "object",
                "properties": {
                    "action": {
                        "type": "string",
                        "enum": ["create", "search", "stats", "delete"],
                        "description": "ìˆ˜í–‰í•  ì‘ì—… ì¢…ë¥˜"
                    },
                    "db_path": {
                        "type": "string",
                        "description": "Vector DB ê²½ë¡œ",
                        "default": self.tool_config["db_path"]
                    },
                    "query": {
                        "type": "string",
                        "description": "ê²€ìƒ‰ ì¿¼ë¦¬ (search ì‹œ í•„ìš”)"
                    },
                    "top_k": {
                        "type": "integer",
                        "description": "ë°˜í™˜í•  ìƒìœ„ ê²°ê³¼ ìˆ˜",
                        "default": 5
                    },
                    "chunks_file": {
                        "type": "string",
                        "description": "ì²­í¬ íŒŒì¼ ê²½ë¡œ (create ì‹œ í•„ìš”)"
                    }
                },
                "required": ["action"]
            }
        }

    async def execute(self, arguments: Dict[str, Any]) -> str:
        """Tool ì‹¤í–‰"""
        try:
            action = arguments.get("action")
            db_path = Path(arguments.get("db_path", self.tool_config["db_path"]))

            logger.info(f"ğŸ—„ï¸ VectorDB ì‘ì—…: {action}")

            if action == "create":
                return await self._create_db(db_path, arguments)
            elif action == "search":
                return await self._search_db(db_path, arguments)
            elif action == "stats":
                return await self._get_stats(db_path)
            elif action == "delete":
                return await self._delete_db(db_path)
            else:
                return f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì‘ì—…: {action}"

        except Exception as e:
            logger.error(f"VectorDB ì‘ì—… ì‹¤íŒ¨: {e}")
            return f"âŒ VectorDB ì‘ì—… ì‹¤íŒ¨: {str(e)}"

    async def _create_db(self, db_path: Path, args: Dict[str, Any]) -> str:
        """Vector DB ìƒì„±"""
        chunks_file = args.get("chunks_file")
        if not chunks_file:
            return "âŒ chunks_fileê°€ í•„ìš”í•©ë‹ˆë‹¤."

        chunks_file = Path(chunks_file)
        if not chunks_file.exists():
            return f"âŒ ì²­í¬ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {chunks_file}"

        # ì²­í¬ íŒŒì¼ ë¡œë“œ
        with open(chunks_file, 'r', encoding='utf-8') as f:
            chunks_data = json.load(f)

        chunks = chunks_data["chunks"]
        total_chunks = len(chunks)

        # FAISS ì¸ë±ìŠ¤ ìƒì„± ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(1)

        # ë©”íƒ€ë°ì´í„° ì €ì¥
        db_path.mkdir(parents=True, exist_ok=True)
        metadata_file = db_path / "metadata.json"

        metadata = {
            "dimension": self.tool_config["dimension"],
            "metric": self.tool_config["metric"],
            "total_vectors": total_chunks,
            "index_type": self.tool_config["index_type"],
            "source_chunks": str(chunks_file),
            "created_at": str(asyncio.get_event_loop().time())
        }

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2)

        # ì¸ë±ìŠ¤ íŒŒì¼ ì‹œë®¬ë ˆì´ì…˜
        index_file = db_path / "index.faiss"
        with open(index_file, 'w') as f:
            f.write(f"FAISS Index Simulation - {total_chunks} vectors")

        return f"""âœ… Vector DB ìƒì„± ì™„ë£Œ

ğŸ“Š DB ì •ë³´:
- ê²½ë¡œ: {db_path}
- ë²¡í„° ì°¨ì›: {metadata['dimension']}
- ì´ ë²¡í„° ìˆ˜: {total_chunks}
- ë©”íŠ¸ë¦­: {metadata['metric']}
- ì¸ë±ìŠ¤ íƒ€ì…: {metadata['index_type']}

ğŸ“ ìƒì„±ëœ íŒŒì¼:
- ë©”íƒ€ë°ì´í„°: {metadata_file}
- ì¸ë±ìŠ¤: {index_file}
- ì†ŒìŠ¤ ì²­í¬: {chunks_file}"""

    async def _search_db(self, db_path: Path, args: Dict[str, Any]) -> str:
        """Vector DB ê²€ìƒ‰"""
        query = args.get("query")
        top_k = args.get("top_k", 5)

        if not query:
            return "âŒ queryê°€ í•„ìš”í•©ë‹ˆë‹¤."

        if not db_path.exists():
            return f"âŒ Vector DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}"

        # ê²€ìƒ‰ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.5)

        # ìƒ˜í”Œ ê²€ìƒ‰ ê²°ê³¼
        results = [
            {"id": 0, "score": 0.95, "text": "VirtualFab digital twin implementation..."},
            {"id": 1, "score": 0.89, "text": "Semiconductor manufacturing optimization..."},
            {"id": 2, "score": 0.87, "text": "Predictive maintenance using ML..."}
        ][:top_k]

        return f"""âœ… Vector DB ê²€ìƒ‰ ì™„ë£Œ

ğŸ” ì¿¼ë¦¬: "{query}"
ğŸ“Š ë°˜í™˜ ê²°ê³¼ ìˆ˜: {len(results)}

ğŸ“ ê²€ìƒ‰ ê²°ê³¼:
{chr(10).join(f"{i+1}. [ì ìˆ˜: {r['score']:.3f}] {r['text'][:100]}..." for i, r in enumerate(results))}"""

    async def _get_stats(self, db_path: Path) -> str:
        """DB í†µê³„ ì •ë³´"""
        if not db_path.exists():
            return f"âŒ Vector DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}"

        metadata_file = db_path / "metadata.json"
        if metadata_file.exists():
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
        else:
            metadata = {"total_vectors": 0, "dimension": self.tool_config["dimension"]}

        # íŒŒì¼ í¬ê¸° ê³„ì‚°
        total_size = sum(f.stat().st_size for f in db_path.glob("*") if f.is_file())

        return f"""ğŸ“Š Vector DB í†µê³„

ğŸ“ ê²½ë¡œ: {db_path}
ğŸ“ ì´ í¬ê¸°: {total_size} bytes ({total_size/1024/1024:.2f} MB)
ğŸ”¢ ë²¡í„° ìˆ˜: {metadata.get('total_vectors', 0)}
ğŸ“ ì°¨ì›: {metadata.get('dimension', self.tool_config['dimension'])}
ğŸ“Š ë©”íŠ¸ë¦­: {metadata.get('metric', self.tool_config['metric'])}
ğŸ—ï¸ ì¸ë±ìŠ¤ íƒ€ì…: {metadata.get('index_type', self.tool_config['index_type'])}

ğŸ“… ìƒì„±ì¼: {metadata.get('created_at', 'ì•Œ ìˆ˜ ì—†ìŒ')}"""

    async def _delete_db(self, db_path: Path) -> str:
        """Vector DB ì‚­ì œ"""
        if not db_path.exists():
            return f"âŒ Vector DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_path}"

        # ì‚­ì œ ì‹œë®¬ë ˆì´ì…˜
        await asyncio.sleep(0.2)

        # ì‹¤ì œë¡œëŠ” shutil.rmtree ì‚¬ìš©
        return f"""âœ… Vector DB ì‚­ì œ ì™„ë£Œ

ğŸ—‘ï¸ ì‚­ì œëœ ê²½ë¡œ: {db_path}
âš ï¸ ì‹¤ì œ íŒŒì¼ ì‚­ì œëŠ” ì•ˆì „ì„ ìœ„í•´ ìˆ˜ë™ìœ¼ë¡œ ìˆ˜í–‰í•˜ì„¸ìš”."""