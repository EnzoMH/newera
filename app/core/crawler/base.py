"""
Base Crawler Abstract Class
ëª¨ë“  í¬ë¡¤ëŸ¬ì˜ ê¸°ë³¸ ì¸í„°í˜ì´ìŠ¤ ì •ì˜
"""
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
from pathlib import Path
import logging

logger = logging.getLogger(__name__)


class BaseCrawler(ABC):
    """
    í¬ë¡¤ëŸ¬ ê¸°ë³¸ ì¶”ìƒ í´ë˜ìŠ¤
    ëª¨ë“  í¬ë¡¤ëŸ¬ëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ êµ¬í˜„
    """

    def __init__(self, output_dir: Optional[Path] = None):
        """
        Args:
            output_dir: í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.output_dir = Path(output_dir) if output_dir else None
        if self.output_dir:
            self.output_dir.mkdir(parents=True, exist_ok=True)

    @abstractmethod
    async def crawl(self, **kwargs) -> List[Dict[str, Any]]:
        """
        í¬ë¡¤ë§ ì‹¤í–‰ (ì¶”ìƒ ë©”ì„œë“œ)

        Returns:
            í¬ë¡¤ë§ëœ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        pass

    @abstractmethod
    def get_source_name(self) -> str:
        """
        í¬ë¡¤ëŸ¬ ì†ŒìŠ¤ ì´ë¦„ ë°˜í™˜

        Returns:
            ì†ŒìŠ¤ ì´ë¦„ (ì˜ˆ: "arxiv", "pubmed" ë“±)
        """
        pass

    def save_results(self, results: List[Dict[str, Any]], filename: Optional[str] = None) -> Path:
        """
        í¬ë¡¤ë§ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥

        Args:
            results: ì €ì¥í•  ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            filename: ì €ì¥í•  íŒŒì¼ëª… (ì—†ìœ¼ë©´ ìë™ ìƒì„±)

        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        if not self.output_dir:
            raise ValueError("output_dirê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        import json
        from datetime import datetime

        if not filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.get_source_name()}_{timestamp}.json"

        file_path = self.output_dir / filename
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)

        logger.info(f"ğŸ’¾ í¬ë¡¤ë§ ê²°ê³¼ ì €ì¥: {file_path}")
        return file_path

